# The-Inator-Toolkit
A repository for all of my different small bioinformatic tools that help with everyday bioinformatic tasks.
![alt text](https://github.com/BenMinch/The-Inator-Toolkit/blob/main/images/Screen%20Shot%202023-02-23%20at%2010.04.04%20PM.png)
# Corrilation-inator
A program that takes two matrices of expression data (or other data) and looks at total correlation between them. This will do spearman's correlation (if you want pearson's it's an easy change.

### Dependencies
Pandas
Numpy

### Use cases
1) You have metatranscriptomic and metagenomic mapping data for a certain gene over time and you want to see if they are correlated.
2) You have mapping data from two different sites on a specific organism over time and want to see correlation.
3) You have a matrix of environmental data you want to correlate with metagenomic expression or metatranscriptomics.

### Inputs
1) Two .csv files that have identical columns for the two datasets you want to correlate. They should have a column called "Contig" that has all your sample names in it, the rest of the columns have to be numerical and must match sample length.
2) Output name: can be whatever you want to call it

### Outputs
1) A csv file showing the correlation coefficient and p-value for each individual row (sample) in your data
2) A similar csv showing correlation between z-score transformed data.

### Example run
`python corrillationinator.py -g input_file_1.csv -t input_file_2.csv -o outputname`


# CoverM_Genome-inator
This is a simple program that allows you to run coverM genome (a mapping and coverage tool) on a directory of genomes and with a large directory of reads.

### Inputs
1. -i: A directory of genome fasta files that you want to map reads to.
2. -o: Output directory where all your coverM coverage files will go
3. -r: A directory with all your reads in it (fastq format and can be zipped).
4. -minid: Percent identity with which you want to map reads to (i.e. 95%). This must be a number from 0-100. 

### Outputs
A coverM coverage file containing a separate row for each genome, and columns for relative abundance, covered bases, count, and rpkm. This file can then be processed further with GEMAP.py (another one of my programs) if you have time series genomic data.

### Example run
`python CoverM_Genominator.py -i genomes/ -o map_out/ -r input_reads/ -minid 95`

# HMM Parse-inator
A simple script for parsing the tblout file from an hmmscan using HMMER3. 

### Inputs
Just the path to the input file and what you want to call the output file is needed.

### Outputs
The output will be an easy-to-read csv file with a bunch of information including columns for evalue, and ID of the hit (these are the most important columns).

### Example run
`python hmm_parsinator.py input_file outname`

# Seqkit Grep-inator
A very useful program if you have a list of genes and their respective genomes that they are found in and you want to extract all the sequences. This can be useful if you want to establish a reference genome for mapping reads to. Here is the pipeline I commonly use.
### Use cases
Lets say for example, I have an assembled contig and I want to extract out all the MCP (major capsid proteins) for read mapping. This is what I would do.
1) Predict proteins with prodigal.
2) Run the proteins through an HMM search to identify MCP proteins.
3) Get all these proteins together into a file.
4) Using, the information in the fasta headers generated from prodigal, I can make a list of gene names and the sample where that gene came from.
5) I would then use this list to feed into Seqkit Grep-inator and it will find all the genes and extract them into a folder.
6) I can then map reads to this reference set of proteins.

### Inputs
1) Input directory where all of your .fna files are for prodigal (or in general wherever the fasta files are where you want to search).
2) An output directory where you want the extracted genes to go.
3) A list csv file with two columns, one titled "Sample" and one titled "Gene". 

### Outputs
A bunch of fasta files with all the genes you extracted from the list. I usually combine them all together at the end.

### Example run
`python seqkit_grepinator.py input_folder outfolder genelist.csv`

# Unique-inator
This tool is used if you have two sites and want to see genes shared between sites (can also be used for genomes). You are basically parsing through a dRep output file or a cd-hit output file to find genomes or genes that are unique to each of your sample sites.

### Inputs
1) -i: input file, either a dRep Cdb.csv file (generated by the program) or a parsed cd-hit file (see my unCLSTR program as it does this for you and it will be the perfect input for this).
2) -s: sites: this is a comma separated string of your 2 different samples you are trying to decluster (example: `-s site1,site2`). This is essentially a flag to identify both of your samples and therefore must be present in all of the headers of the respective sequences. It is a good recommendation to add these identifier flags onto your sequences before clustering.
3) -d: datatype; either 'drep' for dRep file or CD for cd-hit file.

### Outputs
3 text files will be output containing the members that belong to site 1 only, site 2 only, and that are shared between the two. It will also print a number to the screen of how many fall into each category.

### Example run
`python uniqueinator.py -i Cdb.csv -s site1,site2 -d drep`
